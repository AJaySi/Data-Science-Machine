Draft 2
Psuedo code
def Make_Features(target, caller):
	for y_i in related entities y_0...y_n:
		Make_Features(y_i, target)

	Make_Aggregate_Features(target)
	Make_Entitiy_Features(target)
	Make_Flat_Features(target, caller)

	return target.features

def Make_Aggregate_Features(target):
	for y_i where entity y_i has foreign key referencing target:
		for each pair (func, filter_func) defined by user:
			target.add_agg_feature(y_i, func, filter_func)

	return target.features

def Make_Entitiy_Features(target):
	for each row_func defined by user:
		target.add_row_feature(target, row_func)
	
	for each pair (func, group_by) defined by user:
		target.add_group_feature(y_i, func, group_by)

	return target.features

def Make_Flat_Features(target, caller):
	for y_i where entity y_i is referenced by a foreign key of target:
		if y_i != caller:
			target.add_flat_feature(y_i)

	return target.features


Algorithm
Here I describe a recursive algorithm, Make_Features(target, caller), for generating feature vectors for a target entity in a dataset of structured knowledge. The function will return enough information to construct a feature vector for the target entity. This includes not only feature values, but all the metadata about how each feature was created. If provided, it will take in to account a caller entity, which is the entity that is making the request for features. 

To generate the features for a given entity x, we must recursively Make_Features(y_i, x) for all related entitity, y_0...y_n where y_i != caller. A entity is considered related if either (1) are referenced by a foreign key in x or (2) have a foreign key referencing x. For all new features, the algorithm return complete information on how that that feature was created. 

After compleating the recursive call, the outline for Make_Features(target, caller) is to generate 3 types of features in the following order: (1) Make_Aggregate_Features(target, caller), (2) Make_Entitiy_Features(target, caller), and (3) Make_Flat_Features(target, caller). 

First, Make_Aggregate_Features(target) make features that are calculated by aggregating child entities that reference the target entity. An aggregation function takes a required function to apply to the aggregated entities, as well as an optional filter function to specify a subset of all children to pass to the aggregate function. Any example of an aggregation function is calculating sum of a given column, a, in all related child entities that have a different column, b, equal to value c. 

Second, Make_Entitiy_Features(target) makes features that only consider instances of the provided target entity. These entity features break down into two types. (1) Instance features that look at a single instance of the entity and (2) Group features that consider multiple instances of the entity. Group features optionally define a function that groups instances before applying a feature calculation. An example of an instance feature is converting a date field to the day of the week that it occurs. An example of type (2) is calculating the percentile of column a in given instance relative to all other instances with the same value in column b.

Third, Make_Flat_Features(target, caller) denormalizes the data in target entity.  Denormalizing means replacing a foreign key in a table with the data from the foreign table. This is performed for every foreign table, excluding the calling table. 


Notes on correctness
Make_Row_Features(target, caller) is called after Make_Aggregate_Features to allow those features to be considered. 

Make_Flat_Features(target, caller) should not bring in data from the calling entitiy because that would lead meaningless features when the caller entity performs the aggregation on the target entity. It is important that the algorithm has already made the recursive call to all the entities who will be flattened into the target because that means we have already generated the relevent features to be brought in.





























Draft 1

**Graph setup**

This algorithm generates new feature columns for rows in a given table.

First, we define a graph where each node is a table in the database. There is an edge between nodes if there is some sort of foreign key relationship between them.

**Make feature paths**
To generate the new columns we start at the node we want to generate new columns for and start building feature paths.

A feature path is an ordered list of nodes in the graph that can by joined (the sql sense of the word) to create a new table that contains the data necessary for aggregation.


This path contains infromation on the nodes that are a part of it, as well as the columns of interest. There are two types of columns, the algorithm is interested in. First, it looks for variables that will be the values to make a new column out out. Second, it will look for categorical variables that it can filter the first type of variable by.

To identify categorical variables in a table uses two metrics

- The number of distict values in the column
- The ratio of distinct values to total values

If a column is below the a determined threshhold for both of these metrics, it is determined to be a categorical column.


After all nodes have been added to a feature path, the algorithm does one more pass looking for more categorical variables. This is because categorical variable do not necessarily have to be a part of the path. This second pass looks for categories that connected to the path but not part of it. in example 1, the title category is not in any feature path.

**Calculate new values**
Finally, we must create the new columns for the target table.

To this we iterate over each feature path and add in the columns it provides.

For each feature path, we iterate over the value columns and perform the statistical functions on the all rows such as average, std, or max value.

For each of these columns we create a new feature columns that is fitered by different categorical variable values. To this, we look at each distinct value of a categorical variable and only aggregate rows that match that constraint. This results in several new columns being created for 





Example 1
For example, if we look at the employees database provided by mysql.org.